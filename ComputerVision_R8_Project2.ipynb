{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComputerVision_R8_Project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZWpQv1OwqYK",
        "outputId": "ea69761c-713b-4b30-d7f2-c089a8e68ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#Import necessary libraries to fetch the train and test data...\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVhB9OopxFbX",
        "outputId": "c09ef09c-ab78-4195-90e8-26d132a3c1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/Colab Notebooks/Computer Vision/Project 2 - Dog Breed/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NHq1iBCfFjE",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'test.zip','r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnUMhQrDfJmz",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'sample_submission.csv.zip','r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G9RIxB-fOLT",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'labels.csv.zip','r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJc1lVrW_jmL",
        "colab_type": "text"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmlJ2VMY96IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_labels = pd.read_csv('/content/labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvb1RSc96If",
        "colab_type": "code",
        "outputId": "6a1d7212-562d-46d1-980e-7a1567b1f77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_labels.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2naXlr96Im",
        "colab_type": "code",
        "outputId": "4a39e5f1-3cef-4aeb-db30-8e1ca53be02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('The total count of Dogs: ', df_labels.shape[0])\n",
        "print('The number of Dog Breeds: ', len(df_labels.breed.unique()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total count of Dogs:  10222\n",
            "The number of Dog Breeds:  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLm3W5RN96Ir",
        "colab_type": "code",
        "outputId": "62690616-1956-4f54-e492-b193a1effc31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print('The count of Dogs in each Dog Breed:')\n",
        "df_labels.groupby('breed').size()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The count of Dogs in each Dog Breed:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "breed\n",
              "affenpinscher                      80\n",
              "afghan_hound                      116\n",
              "african_hunting_dog                86\n",
              "airedale                          107\n",
              "american_staffordshire_terrier     74\n",
              "                                 ... \n",
              "welsh_springer_spaniel             79\n",
              "west_highland_white_terrier        81\n",
              "whippet                            95\n",
              "wire-haired_fox_terrier            82\n",
              "yorkshire_terrier                  82\n",
              "Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48iAcY196I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get lable encoding for labels\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df_labels.breed)\n",
        "df_labels['breedEncoded'] = le.transform(df_labels.breed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZhW6HwqEB0e",
        "colab_type": "code",
        "outputId": "cba5f3a6-f2c4-4335-d957-1330db771a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_labels.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "      <th>breedEncoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed  breedEncoded\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull            19\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo            37\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese            85\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick            15\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever            49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N-ecw1PEFow",
        "colab_type": "code",
        "outputId": "401fe78c-5c9f-4717-dd56-253b3e7d5652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "labels = tf.keras.utils.to_categorical(df_labels.breedEncoded)\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlWmRNM96I8",
        "colab_type": "code",
        "outputId": "16cf5543-3d50-4344-9d96-046f0aa4ee1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaJ9naXfoiU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "ImgCnt = df_labels.shape[0]\n",
        "\n",
        "for i in range(ImgCnt):\n",
        "  try:\n",
        "    dummy = cv2.imread('/content/train/'+df_labels.id[i]+'.jpg')\n",
        "    dummy = cv2.resize(dummy,(128,128)) # resize to have all the images of same size\n",
        "    X_train.append(dummy)\n",
        "  except exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkkZEpOe0ipk",
        "outputId": "5673d44e-2036-4fef-a95a-094ee4a233b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('x_train Count: ', len(X_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train Count:  10222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioWDEgElBOs",
        "colab_type": "text"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {}
      },
      "source": [
        "#Convert the list to numpy array for easy manipulation...\n",
        "X_train_arr = np.asarray(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "316WjcTRF-oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_std = X_train_arr/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX_Ww4qNF-kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_std = X_train_std.reshape(X_train_std.shape[0], 128, 128, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWx-pgV96Jv",
        "colab_type": "code",
        "outputId": "9a9044a1-23ff-4688-9ceb-3610734b268c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_std, labels, test_size=0.2, random_state=2)\n",
        "print (\"No. of images in train dataset: \", len(X_train_split))\n",
        "print (\"No. of images in Validation dataset: \", len(X_val_split))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of images in train dataset:  8177\n",
            "No. of images in Validation dataset:  2045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {}
      },
      "source": [
        "test_img = pd.read_csv('/content/sample_submission.csv')['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtTEGqRjGUlg",
        "colab_type": "code",
        "outputId": "7093d61a-ab1e-4c8f-a1bf-f27c962b1090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_img.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    000621fb3cbb32d8935728e48679680e\n",
              "1    00102ee9d8eb90812350685311fe5890\n",
              "2    0012a730dfa437f5f3613fb75efcd4ce\n",
              "3    001510bc8570bbeee98c8d80c8a95ec1\n",
              "4    001a5f3114548acdefa3d4da05474c2e\n",
              "Name: id, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJqZIMbm0Jo",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyYeycTHCKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_feature = []\n",
        "ImgCnt = len(test_img)\n",
        "\n",
        "for i in range(ImgCnt):\n",
        "  try:\n",
        "      img = cv2.imread('/content/test/' + test_img[i] + '.jpg')\n",
        "      img_resize = cv2.resize(img,(128,128)) #resize to have all the images of same size\n",
        "      x_test_feature.append(img_resize)\n",
        "  except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "colab": {}
      },
      "source": [
        "#x_test_feature = []\n",
        "#i = 0 # initialisation\n",
        "#for f in tqdm(test_img.values): # f for format ,jpg\n",
        "#    img = cv2.imread('./test/{}.jpg'.format(f), 0)\n",
        "#    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
        "#    x_test_feature.append(img_resize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9My6qSyDnE-_",
        "colab_type": "text"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93n-IntMnJGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the list to numpy array for easy manipulation...\n",
        "X_test_arr = np.asarray(x_test_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBoMk9dyH4WI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_std = X_test_arr/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "544FhiecH4NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_std = X_test_std.reshape(X_test_std.shape[0], 128, 128, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2jxTY2S96J4",
        "colab_type": "code",
        "outputId": "21ff8ca7-870d-4403-8b2d-88b927b7fad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
        "model.add(Conv2D(filters=64, kernel_size=3))\n",
        "\n",
        "model.add(Flatten()) \n",
        "\n",
        "# fully connected layer\n",
        "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
        "model.add(Dense(units = 120, activation = 'softmax'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BAvCzo96J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8EXw6_oqpR",
        "colab_type": "text"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriIc37NozbK",
        "colab_type": "code",
        "outputId": "6f5c8d05-ce43-49bc-f3da-1e54a0e0ad44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PR9j5_Xozmd",
        "colab_type": "code",
        "outputId": "35d55cbe-2469-4cb8-99af-0bb6f8d6b953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "history = model.fit(X_train_split, y_train_split,\n",
        "                    epochs=10, \n",
        "                    validation_data=(X_val_split, y_val_split),\n",
        "                    verbose = 1,\n",
        "                    batch_size=128)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 8177 samples, validate on 2045 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8177/8177 [==============================] - 30s 4ms/step - loss: 15.8102 - acc: 0.0079 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 2/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 3/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 4/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 5/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 6/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 7/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 8/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 9/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n",
            "Epoch 10/10\n",
            "8177/8177 [==============================] - 12s 1ms/step - loss: 15.9841 - acc: 0.0083 - val_loss: 16.0078 - val_acc: 0.0068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8hWaKmjoz69",
        "colab_type": "text"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLQVFDP96KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator( rotation_range=90,\n",
        "                 width_shift_range=0.1, height_shift_range=0.1,\n",
        "                 horizontal_flip=True)\n",
        "train_datagen.fit(X_train_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqTlW0qHb3Xb",
        "colab": {}
      },
      "source": [
        "val_datagen = ImageDataGenerator( rotation_range=90,\n",
        "                 width_shift_range=0.1, height_shift_range=0.1,\n",
        "                 horizontal_flip=True)\n",
        "val_datagen.fit(X_val_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehaRgT-96KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow(X_train_split, y_train_split, batch_size=9)\n",
        "val_generator = val_datagen.flow(X_val_split, y_val_split, batch_size=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "outputId": "d77f0d55-9313-414a-a862-6cddf8e4d688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit_generator(train_generator,\\\n",
        "                    epochs=10, steps_per_epoch=300, \\\n",
        "                    verbose=1,validation_data=val_generator, validation_steps = 300)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9569 - acc: 0.0100 - val_loss: 16.0044 - val_acc: 0.0071\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9509 - acc: 0.0104 - val_loss: 16.0104 - val_acc: 0.0067\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 16.0524 - acc: 0.0041 - val_loss: 16.0044 - val_acc: 0.0071\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9330 - acc: 0.0115 - val_loss: 16.0041 - val_acc: 0.0071\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9748 - acc: 0.0089 - val_loss: 16.0163 - val_acc: 0.0063\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 36s 120ms/step - loss: 16.0405 - acc: 0.0048 - val_loss: 16.0104 - val_acc: 0.0067\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9748 - acc: 0.0089 - val_loss: 16.0101 - val_acc: 0.0067\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 36s 121ms/step - loss: 15.9689 - acc: 0.0093 - val_loss: 15.9984 - val_acc: 0.0074\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 36s 120ms/step - loss: 16.0047 - acc: 0.0070 - val_loss: 16.0104 - val_acc: 0.0067\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 36s 120ms/step - loss: 15.9868 - acc: 0.0081 - val_loss: 16.0161 - val_acc: 0.0063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa08d3af0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zmLztqo5DY",
        "colab_type": "text"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSTATrhsAo7L",
        "colab_type": "text"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5JdbW6pIvD",
        "colab_type": "text"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBhz611oReeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras.backend as k\n",
        "# k.set_image_dim_ordering('th')\n",
        "\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrqs0zg7ApNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3d158c45-1e4d-4b48-f0de-ede198f3c662"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 include_top=False, pooling='avg')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EItOlRBGpV_A",
        "colab_type": "text"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQsEBgnlpHjH",
        "colab_type": "code",
        "outputId": "24a544dd-3497-4f95-9b72-a35cb9d5e318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3, None, None)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, None, None)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, None, None)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, None, None)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, None, None)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, None, None)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 128, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 256, None, None)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 256, None, None)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 256, None, None)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 256, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 512, None, None)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 512, None, None)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 512, None, None)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 512, None, None)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHpeOyW0qauW",
        "colab_type": "text"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BpT4MLkqoaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_model():\n",
        "   #Create your own input format\n",
        "    input = Input(shape=(3, 128, 128),name = 'image_input')\n",
        "\n",
        "    #Use the generated model \n",
        "    output_vgg16_conv = base_model(input)\n",
        "\n",
        "    #Add the fully-connected layers    \n",
        "    #x = Flatten()(output_vgg16_conv)\n",
        "    x = Dense(units=1024, activation = 'relu')(output_vgg16_conv)\n",
        "    x = Dense(units=256, activation = 'relu')(x)\n",
        "    o = Dense(units = 120, activation = 'softmax')(x)\n",
        "    model = Model(input=input, output=[o])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpkkH7HoOrv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "be55dcd9-85fa-412b-cf4c-70e925b95287"
      },
      "source": [
        " model_Final = gen_model()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=[<tf.Tenso...)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqH5vSAVtKcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f792c1ff-ac2b-4c29-9d1f-a2b6ccdaeef8"
      },
      "source": [
        "model_Final.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_input (InputLayer)     (None, 3, 128, 128)       0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,533,240\n",
            "Trainable params: 15,533,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQem0pHITIj",
        "colab_type": "text"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP9lRk8PtSN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a42e5dbf-d49f-4958-f2b9-8a16eb8a9c93"
      },
      "source": [
        "for layer in model_Final.layers:\n",
        "  print (layer.name)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image_input\n",
            "vgg16\n",
            "dense_3\n",
            "dense_4\n",
            "dense_5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Vlr88XPjfp",
        "colab_type": "code",
        "outputId": "466af29e-efb2-40db-d46c-02e68166a698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model_Final.layers:\n",
        "  if('vgg16' in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "    \n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model_Final.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mimage_input\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mvgg16\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_3\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdense_4\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdense_5\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj-BwqgfIkdv",
        "colab_type": "text"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5fAgVQIpKZ",
        "colab_type": "text"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZk2SWvjIoRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_Final.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzRzo09_Pq83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_split_th = np.rollaxis(X_train_split, 3, 1)  \n",
        "X_val_split_th =  np.rollaxis(X_val_split, 3, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkyOUAsrPqvF",
        "colab_type": "code",
        "outputId": "5016da56-b015-4a2c-877b-0b931fac001f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "history = model_Final.fit(X_train_split_th, y_train_split,\n",
        "                    epochs=10, \n",
        "                    validation_data=(X_val_split_th, y_val_split),\n",
        "                    verbose = 1,\n",
        "                    batch_size=128)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8177 samples, validate on 2045 samples\n",
            "Epoch 1/10\n",
            "8177/8177 [==============================] - 11s 1ms/step - loss: 4.7295 - acc: 0.0247 - val_loss: 4.5817 - val_acc: 0.0411\n",
            "Epoch 2/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 4.2571 - acc: 0.0753 - val_loss: 4.0726 - val_acc: 0.0885\n",
            "Epoch 3/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 3.7082 - acc: 0.1475 - val_loss: 3.7249 - val_acc: 0.1315\n",
            "Epoch 4/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 3.3688 - acc: 0.1904 - val_loss: 3.4889 - val_acc: 0.1672\n",
            "Epoch 5/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 3.1266 - acc: 0.2358 - val_loss: 3.3614 - val_acc: 0.1785\n",
            "Epoch 6/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 2.9549 - acc: 0.2753 - val_loss: 3.3198 - val_acc: 0.1892\n",
            "Epoch 7/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 2.8299 - acc: 0.2966 - val_loss: 3.2589 - val_acc: 0.2108\n",
            "Epoch 8/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 2.7158 - acc: 0.3132 - val_loss: 3.2782 - val_acc: 0.2044\n",
            "Epoch 9/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 2.6119 - acc: 0.3356 - val_loss: 3.2571 - val_acc: 0.2029\n",
            "Epoch 10/10\n",
            "8177/8177 [==============================] - 8s 1ms/step - loss: 2.5274 - acc: 0.3556 - val_loss: 3.2199 - val_acc: 0.2166\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}